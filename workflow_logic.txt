'''
The pipeline of this project is to follow each of the file for each component, I don't, understand how and why we do it, here the example of data ingestion;

1. Update config.yaml
   data_ingestion:
   root_dir: artifacts/data_ingestion
   source_URL: https://github.com/ChrisEssomba/Text-Summarizer-Project/raw/refs/heads/main/summarizer-data.zip
   local_data_file: artifacts/data_ingestion/data.zip
   unzip_dir: artifacts/data_ingestion

2. Update params.yaml
   key: value #default element

3. Update entity.yaml

from dataclasses import dataclass
from pathlib import Path

@dataclass(frozen=True)
class DataIngestionConfig:
root_dir: Path # Where to store all artifacts related to data ingestion
source_URL: str # Where to download the data from (a remote URL)
local_data_file: Path # Path to save the downloaded ZIP file
unzip_dir: Path # Where to extract the contents of the ZIP

4. Update the configuration manager in src config
   from textSummarizer.constants import \*
   from textSummarizer.utils.common import read_yaml, create_directories

class ConfigurationManager:
def **init**(
self,
config_filepath = CONFIG_FILE_PATH,
params_filepath = PARAMS_FILE_PATH):

        self.config = read_yaml(config_filepath)
        self.params = read_yaml(params_filepath)

        create_directories([self.config.artifacts_root]) #automatically create the folder that will contain the artefacts

    # in the corresponding files we defined some constant values, here we access them !
    def get_data_ingestion_config(self) -> DataIngestionConfig:
        config = self.config.data_ingestion

        create_directories([config.root_dir])

        data_ingestion_config = DataIngestionConfig(
            root_dir= config.root_dir,
            source_URL= config.source_URL,
            local_data_file= config.local_data_file,
            unzip_dir= config.unzip_dir
        )
        return data_ingestion_config

5.  Update the components
    import os
    import urllib.request as request
    import zipfile
    from textSummarizer.logging import logger
    from textSummarizer.utils.common import get_size
    class DataIngestion:
    def **init**(self, config: DataIngestionConfig):
    self.config = config
    def download_file(self):
    if not os.path.exists(self.config.local_data_file):
    filename, headers = request.urlretrieve(
    url = self.config.source_URL,
    filename= self.config.local_data_file
    )
    logger.info(f"{filename} download! with following info: \n{headers}")
    else:
    logger.info(f"File already exists of size: {get_size(Path(self.config.local_data_file))}")

        def extract_zip_file(self):
            """
            Zip_file_path: str
            Extracts the zip file into the data directory
            Function returns None
            """
            unzip_path = self.config.unzip_dir
            os.makedirs(unzip_path, exist_ok=True)
            with zipfile.ZipFile(self.config.local_data_file, 'r') as zip_ref:
                zip_ref.extractall(unzip_path)

6.  Update the pipeline
    from textSummarizer.components.data_ingestion import DataIngestion
    from textSummarizer.config.configuration import ConfigurationManager
    from textSummarizer.constants import \*
    from textSummarizer.entity import (DataIngestionConfig)
    from textSummarizer.utils.common import read_yaml, create_directories

class DataIngestionTrainingPipeline:
def **init**(self):
pass

    #update the pipeline
    def main(self):
        config = ConfigurationManager()
        data_ingestion_config = config.get_data_ingestion_config()
        data_configuration = DataIngestion(config=data_ingestion_config)
        data_configuration.download_file()
        data_configuration.extract_zip_file()

7.  Update the main.py
    from textSummarizer.logging import logger
    from textSummarizer.pipeline.stage_01_data_ingestion import DataIngestionTrainingPipeline
    from textSummarizer.pipeline.stage_02_data_validation import DataValidation, DataValidationTrainingPipeline
    from textSummarizer.pipeline.stage_03_data_transformation import DataTransformationTrainingPipeline

logger.info("Welcome to our app")

STAGE_NAME = "Data Ingestion Stage"
try:
logger.info(f">>>>>> stage {STAGE_NAME} started <<<<<")
data_ingestion = DataIngestionTrainingPipeline()
data_ingestion.main()
logger.info(f">>> stage {STAGE_NAME} completed <<<<<")
except Exception as e:
logger.exception(e)
raise
'''